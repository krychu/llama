# Llama 2 on CPU

This is a fork of https://github.com/facebookresearch/llama that runs on CPU.

Please refer to the official installation and usage instructions as they are exactly the same.

The 7B model infers one words per ~1.5 secs on my MacBook Pro M1.
